{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f54bd49-7753-4ea7-ad64-561c3f04bee9",
   "metadata": {},
   "source": [
    "# Bedrock Knowledge Base Retrieval and Generation with SageMaker Inference and Guardrails\n",
    "\n",
    "## Description\n",
    "This notebook demonstrates how to enhance a Retrieval-Augmented Generation (RAG) pipeline by integrating Amazon SageMaker Inference with Amazon Bedrock. We will walk through the process of querying a knowledge base, using SageMaker for model inference, applying Guardrails to control the generation of responses, and filtering results with metadata to ensure compliance and quality.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f330a12a",
   "metadata": {},
   "source": [
    "![Guardrails](./guardrail.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "import-section",
   "metadata": {},
   "source": [
    "## 1. Import Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "import-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary functions from advanced_rag_utils\n",
    "import boto3\n",
    "from advanced_rag_utils import (\n",
    "    load_variables,\n",
    "    create_standard_filter,\n",
    "    setup_bedrock_client,\n",
    "    retrieve_from_bedrock_with_filter,\n",
    "    format_llama3_prompt,\n",
    "    generate_sagemaker_response,\n",
    "    apply_output_guardrail,\n",
    "    retrieve_generate_apply_guardrails\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4c8ad1-b488-4c6d-9cad-5dbec4e9c674",
   "metadata": {},
   "source": [
    "## 2. Load Configuration Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f715548e-d107-406b-8175-02082fbfe905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load configuration variables from a JSON file\n",
    "variables = load_variables(\"../variables.json\")\n",
    "variables  # Display the loaded variables for confirmation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e81ed4-198a-4884-9f5f-463959d76c49",
   "metadata": {},
   "source": [
    "## 3. Set Up Required IDs and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b8fa96-7072-4b10-ac06-3f9f87f522cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge Base Selection  \n",
    "kb_id = variables[\"kbFixedChunk\"]  # Options: \"kbFixedChunk\", \"kbHierarchicalChunk\", \"kbSemanticChunk\"\n",
    "\n",
    "# Retrieve guardrail details\n",
    "guardrail_id = variables[\"guardrail_id\"]\n",
    "guardrail_version = variables[\"guardrail_version\"]\n",
    "\n",
    "# SageMaker endpoint\n",
    "sagemaker_endpoint = variables['sagemakerLLMEndpoint']\n",
    "\n",
    "# Retrieval-Augmented Generation (RAG) Configuration  \n",
    "number_of_results = 3  # Number of relevant documents to retrieve  \n",
    "generation_configuration = {\n",
    "    \"temperature\": 0,  # Lower temperature for more deterministic responses  \n",
    "    \"top_k\": 10,  # Consider top 10 tokens at each generation step  \n",
    "    \"max_new_tokens\": 5000,  # Maximum number of tokens to generate  \n",
    "    \"stop\": \"<|eot_id|>\"  # Stop sequence to end the response generation  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b616d4-1d81-44ce-af45-f4e188f0539b",
   "metadata": {},
   "source": [
    "## 4. Define Metadata Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f993f-efbd-492a-a5c2-97242d02ff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a standard filter for document type and year\n",
    "metadata_filter = create_standard_filter('10K Report', 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34fd89-baef-4bad-83ba-5820b93c4ca2",
   "metadata": {},
   "source": [
    "## 5. Initialize Bedrock Clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initialize-clients",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Bedrock clients\n",
    "bedrock_agent_client = setup_bedrock_client(variables[\"regionName\"])\n",
    "bedrock_runtime_client = boto3.client(\"bedrock-runtime\", region_name=variables[\"regionName\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cab666-18d4-4c18-9c3f-c7f1b2b2f82f",
   "metadata": {},
   "source": [
    "## 6: Test Guardrails for Investment Advice\n",
    "Let's ask the model for investment advice. When we created the guardrails, we restricted Bedrock from providing any investment advice. Bedrock should return a preconfigured response \"This request cannot be processed due to safety protocols\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aee165-d50d-4cb7-beaa-fff5d35a91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query for testing investment advice restriction\n",
    "query = \"based on your amazon's results should I buy amazon stock?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f12c5f-4477-440f-94a2-fbe36b35bee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the comprehensive function to perform the RAG pipeline with guardrails\n",
    "guardrail_response, raw_response, context = retrieve_generate_apply_guardrails(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    sagemaker_endpoint=sagemaker_endpoint,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    metadata_filter=metadata_filter,\n",
    "    generation_config=generation_configuration,\n",
    "    bedrock_agent_client=bedrock_agent_client,\n",
    "    bedrock_runtime_client=bedrock_runtime_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Print the query and response\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response:\")\n",
    "print(guardrail_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe5dfb7-581f-4264-9024-f6a5a61c8cf7",
   "metadata": {},
   "source": [
    "## 7. Test Guardrails for PII Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed6d7c4-f93e-4692-b8c1-92d595c0c16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query for testing PII anonymization\n",
    "query=\"Who is the current CFO of Amazon?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183f04d-7a31-4753-a73a-7ee7bb97ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the comprehensive function to perform the RAG pipeline with guardrails\n",
    "guardrail_response, raw_response, context = retrieve_generate_apply_guardrails(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    sagemaker_endpoint=sagemaker_endpoint,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    metadata_filter=metadata_filter,\n",
    "    generation_config=generation_configuration,\n",
    "    bedrock_agent_client=bedrock_agent_client,\n",
    "    bedrock_runtime_client=bedrock_runtime_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# Print the query and response\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response (With PII Anonymization):\")\n",
    "print(guardrail_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step-by-step-section",
   "metadata": {},
   "source": [
    "## 8. (Optional) Step-by-Step Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step-by-step-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you prefer to execute the steps individually:\n",
    "\n",
    "# 1. Retrieve context from Bedrock KB with metadata filtering\n",
    "context = retrieve_from_bedrock_with_filter(\n",
    "    query=query,\n",
    "    knowledge_base_id=kb_id,\n",
    "    metadata_filter=metadata_filter,\n",
    "    bedrock_client=bedrock_agent_client,\n",
    "    num_results=number_of_results,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# 2. Format prompt using retrieved context\n",
    "prompt = format_llama3_prompt(query, context)\n",
    "\n",
    "# 3. Generate response using SageMaker endpoint\n",
    "raw_response = generate_sagemaker_response(\n",
    "    prompt=prompt,\n",
    "    endpoint_name=sagemaker_endpoint,\n",
    "    generation_config=generation_configuration\n",
    ")\n",
    "\n",
    "# 4. Apply guardrails to the output\n",
    "guardrail_response = apply_output_guardrail(\n",
    "    output_text=raw_response,\n",
    "    guardrail_id=guardrail_id,\n",
    "    guardrail_version=guardrail_version,\n",
    "    bedrock_client=bedrock_runtime_client,\n",
    "    region_name=variables[\"regionName\"]\n",
    ")\n",
    "\n",
    "# 5. Display results\n",
    "print(\"Question:\", {query})\n",
    "# print(f\"Context: {context}\")  # Uncomment for debugging\n",
    "print(\"\\nRaw Response (Without Guardrails):\")\n",
    "print(raw_response)\n",
    "print(\"\\nGuardrail Response:\")\n",
    "print(guardrail_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
